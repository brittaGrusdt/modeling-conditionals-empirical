var params = {
  alpha: data.alpha,
  gamma: data.gamma,
  theta: data.theta,
  // cost_literal: data.cost_literal,
  // cost_conjunction: data.cost_conjunction,
  // cost_might: data.cost_might,
  // cost_conditional: data.cost_conditional
  p_utts: data.p_utts
}
//var PROLIFIC_IDS = _.uniq(_.map(OBSERVATIONS, 'prolific_id'))
//var TRIALS = _.uniq(_.map(OBSERVATIONS, 'id'))

setParams(params)
// just for debugging
// var invalid_utts_states = check_states_utts(
//   ALL_BNS,
//   _.map(globalStore.utterances, 'utt'),
//   globalStore.thresholds,
//   params,
//   true
// )
var uc_data = data["observed_utts_ratios"]

var par_zoibs = data["likelihoods_zoib"]
var par_gaussian = data["likelihoods_gaussian"]

var zoib_likelihoods = build_Pt_given_context_and_r(par_zoibs, "zero-one-inflated-beta")
var gaussian_likelihoods = build_Pt_given_context_and_r(par_gaussian, "gaussian")
var contexts = _.uniq(_.map(par_zoibs, 'id')).concat(_.uniq(_.map(par_gaussian, 'id')))


if(data["verbose"][0]) {
  display("free parameters:")
  display("alpha: " + globalStore.alpha)
  display("gamma: " + globalStore.gamma)
  display("theta: " + globalStore.thresholds.theta)
  display("theta_might: " + globalStore.thresholds.theta_might)
  // display('vs_utts' + globalStore.utterances)
  // display('ps_utts' + globalStore.ps_utts)
  display('informativeness utterance types:')
  display("# conjunctions: " + globalStore.states_conjunction.length)
  display("# literals: " + globalStore.states_literal.length)
  display("# conditionals: " + globalStore.states_conditional.length)
  display("# mights: " + globalStore.states_might.length)
}

// get Bayes nets used for predictions for each trial + participant
// we sample a certain number of Bayes nets per relation
// (depending on P(r|data), computed beforehand in R)
// // ONE DISTRIBUTION FOR EACH CN: PRIOR CONDITIONED ON CN
var priors_conditioned = map(function(r) {
  var prior_conditioned_r = Infer({model: function() {
      var s = sample(globalStore.state_prior)
      condition(s.r == r)
      return(s)
    }, method: 'enumerate'})
  return([r, prior_conditioned_r])
}, RELATIONS)
var PRIOR_CONDITIONED_R = Object.fromEntries(priors_conditioned)

var POSTERIOR_STATES_CONTEXTS =  get_posterior_given_context(
  PRIOR_CONDITIONED_R, zoib_likelihoods, gaussian_likelihoods, contexts
)
//display(POSTERIOR_STATES_CONTEXTS["if1_uh"])

// RUN MODEL
var rsa_speaker_predictions = run_speaker(ALL_BNS, false)
//var x = rsa_speaker_predictions['-A implies C_unc-high-low_0.006224644725537807_0.550477986004518_0.43128676552264295_0.012010603747301285']

// predictions 4 (close to) certain worlds
var predictions_certain_worlds_list = map(function(bn){
  return([bn.w, rsa_speaker_predictions[bn.bn_id]])
  //return({w: bn.w, prediction: rsa_speaker_predictions[bn.bn_id]})
}, BNS_CERTAIN_WORLD)
var predictions_certain_worlds = Object.fromEntries(predictions_certain_worlds_list)
var speaker_predictions = predictions_with_gamma(rsa_speaker_predictions,
                                                 predictions_certain_worlds)

// get predictions + compute log likelihood of utterance choices given model predictions
var result = map(function(c_i) {
  // some single trials were excluded
  var observations_ci = filter(function(obj){
    return(obj.id == c_i)
  }, uc_data)

  var model_prediction = get_prediction_per_context(
    speaker_predictions, c_i, POSTERIOR_STATES_CONTEXTS
  )
  // display(model_prediction)

  var result_by_ci = {
    ll_ci: get_log_likelihood_by_context(observations_ci, model_prediction),
    p_hat: model_prediction.params.ps,
    utterance: model_prediction.params.vs,
    id: c_i
  }

  return([c_i, result_by_ci])
}, contexts)

//var summed_log_likelihood = sum(_.map(log_likelihood_by_trial, 'll'))


Object.fromEntries(result)
