var params = {
  alpha: data.alpha,
  gamma: data.gamma,
  theta: data.theta,
  // cost_literal: data.cost_literal,
  // cost_conjunction: data.cost_conjunction,
  // cost_might: data.cost_might,
  // cost_conditional: data.cost_conditional
  p_utts: data.p_utts
}
var PROLIFIC_IDS = _.uniq(_.map(OBSERVATIONS, 'prolific_id'))
var TRIALS = _.uniq(_.map(OBSERVATIONS, 'id'))

setParams(params)
// just for debugging
var invalid_utts_states = check_states_utts(
  ALL_BNS,
  _.map(globalStore.utterances, 'utt'),
  globalStore.thresholds,
  params,
  true
)

if(data["verbose"][0]) {
  display("free parameters:")
  display("alpha: " + globalStore.alpha)
  display("gamma: " + globalStore.gamma)
  display("theta: " + globalStore.thresholds.theta)
  display("theta_might: " + globalStore.thresholds.theta_might)
  // display('vs_utts' + globalStore.utterances)
  // display('ps_utts' + globalStore.ps_utts)
  display('informativeness utterance types:')
  display("# conjunctions: " + globalStore.states_conjunction.length)
  display("# literals: " + globalStore.states_literal.length)
  display("# conditionals: " + globalStore.states_conditional.length)
  display("# mights: " + globalStore.states_might.length)
}

// get Bayes nets used for predictions for each trial + participant
// we sample a certain number of Bayes nets per relation
// (depending on P(r|data), computed beforehand in R)
// // ONE DISTRIBUTION FOR EACH CN: PRIOR CONDITIONED ON CN
var priors_conditioned = map(function(r) {
  var prior_conditioned_r = Infer({model: function() {
      var s = sample(globalStore.state_prior)
      condition(s.r == r)
      return(s)
    }, method: 'enumerate'})
  return([r, prior_conditioned_r])
}, RELATIONS)
var PRIOR_CONDITIONED_R = Object.fromEntries(priors_conditioned)

var posterior_states_trial_subj_list = map(function(trial_id){
  var observed_trial = OBSERVATIONS_BY_TRIAL_SUBJ[trial_id]
  var subjects = Object.keys(observed_trial)
  var observations = Object.values(observed_trial)
  var p_s_given_dij = map(function(obs){
    return(posterior_given_slider_rating(obs, PRIOR_CONDITIONED_R))
  }, observations)

  var obj = Object.fromEntries(zip(subjects, p_s_given_dij))
  return([trial_id, obj])
}, TRIAL_IDS)
var POSTERIOR_STATES_TRIAL_SUBJ = Object.fromEntries(posterior_states_trial_subj_list)

// RUN MODEL
var rsa_speaker_predictions = run_speaker(ALL_BNS, false)
//var x = rsa_speaker_predictions['-A implies C_unc-high-low_0.006224644725537807_0.550477986004518_0.43128676552264295_0.012010603747301285']

// predictions 4 (close to) certain worlds
var predictions_certain_worlds_list = map(function(bn){
  return([bn.w, rsa_speaker_predictions[bn.bn_id]])
  //return({w: bn.w, prediction: rsa_speaker_predictions[bn.bn_id]})
}, BNS_CERTAIN_WORLD)
var predictions_certain_worlds = Object.fromEntries(predictions_certain_worlds_list)
var speaker_predictions = predictions_with_gamma(rsa_speaker_predictions,
                                                 predictions_certain_worlds)

// get predictions + compute log likelihood of utterance choices given model predictions
var result = map(function(trial_id) {
  // some single trials were excluded
  var observations_this_trial = filter(function(obj){
    return(obj.id == trial_id)
  }, OBSERVATIONS)
  var subjects = _.map(observations_this_trial, 'prolific_id')
  //display('nb subjects trial ' + trial_id + ": " + subjects.length)

  var result_by_subj = map(function(subj) {
    // first get model predictions for each trial + subject
    var model_prediction = get_prediction_per_trial_and_subj(
      speaker_predictions, trial_id, subj, POSTERIOR_STATES_TRIAL_SUBJ
    )
    //display(model_prediction[0])
    return({
      ll_subj: get_log_likelihood_by_trial_and_subj(model_prediction, trial_id, subj),
      prediction: model_prediction,
      prolific_id: subj
    })
  }, subjects)

  //display(sum(log_likelihood_all_subj))
  return([trial_id, {predictions: result_by_subj,
                     id: trial_id,
                     ll_trial: sum(_.map(result_by_subj, 'll_subj'))}])
}, TRIAL_IDS)

//var summed_log_likelihood = sum(_.map(log_likelihood_by_trial, 'll'))


Object.fromEntries(result)
