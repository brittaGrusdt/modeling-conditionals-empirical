//globalStore.variables = ["A", "C"]
var WORLDS = ["AC", "A-C", "-AC", "-A-C"]

// default is uniform, i.d. A implies C_unif, ...
var DEP_R_PROB =  data["causal_nets_dep"] ? data["causal_nets_dep"] : []// e.g., A implies C_high_high_low
var IND_R_PROB = data["causal_nets_ind"] ? data["causal_nets_ind"] : [] // e.g. A || C_high_low
var CNS = IND_R_PROB.concat(DEP_R_PROB);

var DEP_R = _.uniq(map(function(s){ // A implies C, -A implies C
  return(s.split("_")[0])
}, DEP_R_PROB))
var IND_R = _.uniq(map(function(s){ // A || C
  return(s.split("_")[0])
}, IND_R_PROB))


var RELATIONS = IND_R.concat(DEP_R); // A || C, -A implies C, A implies C

var dep_params = data["conditional_probs"] ? data["conditional_probs"] : []
var PARAMS_CAUSAL_POWER = filter(function(obj){
  return(obj.variable == 'causal_power')
}, dep_params)

var PARAMS_NOISE = filter(function(obj){
  return(obj.variable == 'noise')
}, dep_params)

var PARAMS_MARGINALS  = data["marginals"] ? data["marginals"] : []


// Functions to generate set of model states S //
/**
* put table into format as is expected by model
* @return {object}
  'r': causal relation
  'probability': string that specifies the probability of antecedent when r is
  dependent, and the probability of antecedent and consequent when r is
  independent
  'table': Categorical Distribution object containing table
  'bn_id': derived bn_id of returned state
*/
var build_model_state = function(table, r, prob_str) {
  var Table = Categorical({vs: ["AC", "A-C", "-AC", "-A-C"],
                           ps: [table[0], table[1], table[2], table[3]]})
  var cat = r + "_" + prob_str + "_"
  var id = cat.concat(table.join("_"))
  var cn = r + "_" + prob_str
  return {"r": r, "probability": prob_str, "table": Table, "bn_id": id, "cn": cn}

}

var get_beta = function(params, category) {
  var idx = _.map(params, 'grp').indexOf(category)
  var distr = Beta({a: params[idx].shape1, b: params[idx].shape2})
  return(distr)
}

var model_independent_tables = function(cn) {
  //display('sample independent tables')
  var r_prob = cn.split("_")
  var probs = r_prob[1].split("-")
  var antecedent = probs[0]
  var consequent = probs[1]

  var p_antecedent = sample(get_beta(PARAMS_MARGINALS, antecedent))
  var p_consequent = sample(get_beta(PARAMS_MARGINALS, consequent))

  var table = [p_antecedent * p_consequent,
               p_antecedent * (1 - p_consequent),
               (1 - p_antecedent) * p_consequent,
               (1 - p_antecedent) * (1 - p_consequent)]
  var state = build_model_state(table, r_prob[0], r_prob[1])
  return(state)
}

var model_dependent_tables = function(cn) {
  //display('sample dependent tables')
  var r_prob = cn.split("_")
  var r = r_prob[0]
  var probs = r_prob[1].split("-")
  var antecedent_str = probs[0]
  var causal_power_str = probs[1]
  var noise_str = probs[2]

  //display('antecedent:' + antecedent_str + " causal_power:" + causal_power_str + " noise: " + noise_str)

  var p_antecedent = sample(get_beta(PARAMS_MARGINALS, antecedent_str))
  var causal_power = sample(get_beta(PARAMS_CAUSAL_POWER, causal_power_str))
  var noise = sample(get_beta(PARAMS_NOISE, noise_str))

  // display("P(ant):" + p_antecedent + " causal power: " + causal_power + " noise: " + noise)
  var p_dep_pos = causal_power + noise * (1 - causal_power)
  //display(p_dep_pos)
  //display("r: " + r)

  var table =
    r == "A implies C" ?
      [p_dep_pos * p_antecedent, (1 - p_dep_pos) * p_antecedent,
       noise * (1 - p_antecedent), (1 - noise) * (1-p_antecedent)] :

    r == "-A implies C" ?
      [noise * (1 - p_antecedent), (1 - noise) * (1 - p_antecedent),
       p_dep_pos * p_antecedent, (1 - p_dep_pos) * p_antecedent] :

    r == "C implies A" ?
     [p_dep_pos * p_antecedent, noise * (1 - p_antecedent),
      (1 - p_dep_pos) * p_antecedent, (1 - noise) * (1 - p_antecedent)] :


    r == "-C implies A" ?
     [noise * (1 - p_antecedent), p_dep_pos * p_antecedent,
      (1 - noise) * (1 - p_antecedent), (1- p_dep_pos) * p_antecedent] : undefined;


  var state = build_model_state(table, r, r_prob[1])
  return(state)
}

/**
* generates world states (tables)
* @return {object} : model state as returned by build_model_state
*/
var model_tables =  function(){
  var rdn = flip(0.5)
  var cn = rdn ? uniformDraw(IND_R_PROB) : uniformDraw(DEP_R_PROB);
  var state = rdn ? model_independent_tables(cn) : model_dependent_tables(cn);
  return(state)
}

//

var smooth_extreme_values = function(val_obs){
  var epsilon = 0.000001;
  return((val_obs === 1) ? (1 - epsilon) :
    (val_obs === 0) ? (0 + epsilon) : val_obs)
}

/** @arg P: Categorical Distribution, observed slider rating
** @arg Q: Categorical Distribution, table model state
**/
var get_kulback_leibler = function(P, Q){
  // var worlds = P.params.vs
  // var pw = Vector(P.params.ps)
  // var qw = Vector(Q.params.ps)
  // var log_part = T.log(T.div(pw, qw)) // - infinity must be replaced by 0...!
  // var kl = T.toScalars(T.dot(T.transpose(pw), log_part))
  var kl = sum(map(function(w){
    var pw = P.score(w)
    var qw = Q.score(w)
    var val = pw === -Infinity || qw == -Infinity ? 0 :
      Math.exp(P.score(w)) * (P.score(w) - Q.score(w))
    return(val)
  }, ["AC", "A-C", "-AC", "-A-C"]))
  // display("ps: " + P.params.ps)
  // display("qs: " + Q.params.ps)
  // display("result: " + sum(kl))
  // display("")
  return(kl)
}

// computes causal power (tau) based on noise (beta) and relation (r)
// tau = (p_dep_pos - beta) / (1-beta) derived from: P(c|a) = tau + beta - tau * beta
// example, r: A->C (++); p_dep_pos: P(c|a), beta: P(c|-a)
// there are 3 problematic cases: (1) noise is undefined
// (2) p_dep_pos is undefined (3) beta = 1
var compute_causal_power = function(observed_noise, observed_p_dep_pos, r){
  var noise = (observed_noise[r] === undefined) ? 0 :
    (observed_noise[r] === 1) ? undefined : observed_noise[r]

  // if observed p_dep_pos is undefined, consider p_dep_pos for
  // corresponding negated causal relation (A->C -- for A->C ++), in this example
  // it is equal to 1-noise of the corresponding relation (here: 1-P(c|-a) = P(-c|-a))
  var cp = (observed_p_dep_pos[r] === undefined) ? (1 - observed_noise) :
    (noise === undefined) ? undefined :
    (observed_p_dep_pos[r] - noise) / (1 - noise);
  return(cp)
}

var get_smoothed_vals_dep_nets = function(observed_marginal, observed_noise,
  observed_causal_power, r){
  var vals = {
    marginal: smooth_extreme_values(observed_marginal[r]),
    noise: smooth_extreme_values(observed_noise[r]),
    causal_power: smooth_extreme_values(observed_causal_power[r])
  }
  return(vals)
}

// returns posterior P(s|d_ij)
// @param slider_rating {AC: , A-C: , -AC: , -A-C: }
// @param prior_conditioned_r  e.g., {A implies C: P(s|r=A implies C)}
var posterior_given_slider_rating = function(slider_rating, prior_conditioned_r){
  var observed_pa = slider_rating["AC"] + slider_rating["A-C"]
  var observed_pna = slider_rating["-AC"] + slider_rating["-A-C"]
  var observed_pc = slider_rating["AC"] + slider_rating["-AC"]
  var observed_pnc = slider_rating["A-C"] + slider_rating["-A-C"]

  var observed_marginal = {
    "A implies C": observed_pa,
    "-A implies C": observed_pna,
    "C implies A": observed_pc,
    "-C implies C": observed_pnc
  }
  var observed_p_dep_pos = {
    "A implies C": observed_pa !== 0 ? slider_rating["AC"] / observed_pa : undefined,
    "-A implies C": observed_pna !== 0 ? slider_rating["-AC"] / observed_pna : undefined,
    "C implies A": observed_pc !== 0 ? slider_rating["AC"] / observed_pc : undefined,
    "-C implies A": observed_pnc !== 0 ? slider_rating["A-C"] / observed_pnc : undefined
  }
  var observed_noise = {
    "A implies C": observed_p_dep_pos["-A implies C"],
    "-A implies C":  observed_p_dep_pos["A implies C"],
    "C implies A": observed_p_dep_pos["-C implies A"],
    "-C implies A":  observed_p_dep_pos["C implies A"]
  }
  // use conditional probability if causal power cannot be computed due to undefined noise
  var observed_causal_power = {
    "A implies C": compute_causal_power(observed_noise, observed_p_dep_pos, "A implies C"),
    "-A implies C": compute_causal_power(observed_noise, observed_p_dep_pos, "-A implies C"),
    "C implies A": compute_causal_power(observed_noise, observed_p_dep_pos, "C implies A"),
    "-C implies A": compute_causal_power(observed_noise, observed_p_dep_pos, "-C implies A")
  }

  var smoothed_obs = {
    "A implies C": get_smoothed_vals_dep_nets(observed_marginal, observed_noise, observed_causal_power, "A implies C"),
    "-A implies C": get_smoothed_vals_dep_nets(observed_marginal, observed_noise, observed_causal_power, "-A implies C"),
    "C implies A": get_smoothed_vals_dep_nets(observed_marginal, observed_noise, observed_causal_power, "C implies A"),
    "-C implies A": get_smoothed_vals_dep_nets(observed_marginal, observed_noise, observed_causal_power, "-C implies A"),
    "A || C": {pa: smooth_extreme_values(observed_pa),
               pc: smooth_extreme_values(observed_pc)}
  }

  var observed_table = Categorical({
    vs: ["AC", "A-C", "-AC", "-A-C"],
    ps: [slider_rating["AC"],
         slider_rating["A-C"],
         slider_rating["-AC"],
         slider_rating["-A-C"]]
  })

  var posterior = Infer({model: function() {
    //var r = uniformDraw(RELATIONS);
    var rdn = flip(0.5)
    var r = rdn ? uniformDraw(IND_R) : uniformDraw(DEP_R);
    var s = sample(prior_conditioned_r[r]); // state with relation r
    //var kl_divergence = get_kulback_leibler(observed_table, s.table)
    //display(kl_divergence)

    var probs_str = s.probability.split("-")
    var p_marginal = probs_str[0]

    // compute LIKELIHOODS:
    if(r == "A || C"){
      var logL_a = get_beta(PARAMS_MARGINALS, p_marginal).score(smoothed_obs[r]["pa"]);
      var prob_c = probs_str[1]
      var logL_c = get_beta(PARAMS_MARGINALS, prob_c).score(smoothed_obs[r]["pc"]);

      // when independent P(A,C) should be close to P(A) * P(C)
      var prod_ac = observed_pa * observed_pc
      var observed_ac = slider_rating["AC"]
      // mean beta-distribution: shape1 / (shape1 + shape2)
      // should be equal to ideal value, i.e. prod_ac
      // => shape1 = (prod_ac * shape2) / (1-prod_ac)

      // when ideal value (prod_ac) is 0 -> use default distribution for low: beta(1, 10)
      // when ideal value (prod_ac) is 1 -> use default distribution for high: beta(10, 1)
      // var shape2 = prod_ac == 0 ? 10 : 1;
      // var shape1 = prod_ac == 1 ? 10 :
      //              prod_ac == 0 ? 1 : (prod_ac * shape2) / (1 - prod_ac);
      // var logL_ac = Beta({a: shape1, b: shape2}).score(
        //   smooth_extreme_values(slider_rating["AC"])
        // );
      // values were fitted to observed values for P(A,C)-P(A)*P(C) in
      // independent conditions
      var logL_ac = Gaussian({mu: 0, sigma: 0.009}).score(observed_ac - prod_ac)
      var logL = logL_a + logL_c + logL_ac
      //factor(logL - kl_divergence)
      factor(logL)
    } else {
      var p = smoothed_obs[r]["marginal"];
      var logL_marginal = get_beta(PARAMS_MARGINALS, p_marginal).score(p);

      // causal power
      var cp = probs_str[1]
      var causal_power_obs = smoothed_obs[r]["causal_power"];
      // if p_dep_pos is undefined (i.e. causal power is undefined),
      // this dependent relation is impossible
      var logL_cp = causal_power_obs === undefined ? -Infinity :
        get_beta(PARAMS_CAUSAL_POWER, cp).score(causal_power_obs);
      // noise
      var noise = probs_str[2]
      var noise_obs = smoothed_obs[r]["noise"];
      var logL_noise = (noise_obs === undefined) ? 0 :
        get_beta(PARAMS_NOISE, noise).score(noise_obs);

      var logL = logL_marginal + logL_cp + logL_noise
      //display(s.bn_id + " " + logL)
      //factor(logL - kl_divergence)
      factor(logL)
    }
    return(s)
  }})
  return(posterior)
}

var get_P_r_given_context = function(context){
  // var p = 1/RELATIONS.length
  // var distr = Categorical({vs: RELATIONS,
  //                          ps: repeat(RELATIONS.length, function() {p})})
  // var distr = Categorical({vs: ["A implies C", "C implies A", "A || C"],
  //                          ps: [1/3, 1/3, 1/3]})
  //
  var distr = context.includes("independent") ?
   Categorical({vs: ["A || C"], ps: [1]}) :
   //context.includes("if1") ? Categorical({vs: ["A implies C"], ps: [1]}) :
   context.includes("if") ? Categorical({vs: ["A implies C", "C implies A"],
                                         ps: [0.5, 0.5]}) :
                                             error("unknown context:" + context);
  return(distr)
}

// builds Probability distribution-objects for each context and probability
// (e.g., if1_uh and P(b|g))
// example return value: {if1_uh: {'AC': {Beta: , Bernoulli: , Categorical: },
//                                 'A-C': ...},
//                        ind_hl: {blue: {Beta: , Bernoulli, Categorical: }, ..}
// @param distribution string 'zero-one-inflated-beta' or 'bernoulli'
var build_Pt_given_context_and_r = function(params, distribution){
  var contexts = _.uniq(_.map(params, 'id'))
  //display(contexts)

  // likelihoods by contexts
  var likelihoods = map(function(c_i){
    var par_ci = filter(function(par){
        return(par.id == c_i)
    },  params)
    //display(c_i + ": " + par_ci.length + "probabilities")

    var likelihood_ci_p = map(function(pars){

      var distrs = distribution == "zero-one-inflated-beta" ?
        [pars.p, {"Categorical": Categorical({vs: ["Bernoulli", "Beta"],
                                              ps: [pars.alpha, 1 - pars.alpha]}),
                  "Bernoulli": Bernoulli({p: pars.gamma}),
                  "Beta": Beta({a: pars.shape1, b: pars.shape2})}] :
        distribution == "bernoulli" ? [pars.p, Bernoulli({p: pars.theta})] :
          error("only zero-one-inflated-beta and bernoulli likelihoods implemented.");

      return(distrs)
    }, par_ci)

    var p_to_distrs = Object.fromEntries(likelihood_ci_p)

    return([c_i, p_to_distrs])
  }, contexts)

  var context_to_p_to_distrs = Object.fromEntries(likelihoods)
  return(context_to_p_to_distrs)
}



/**
* Default context prior over world states
* states are forward-sampled
* @return {Distribution}
*/
var state_prior = function(){
  Infer({method: 'forward', samples: globalStore.n_prior_samples,
         model: model_tables});
}


/**
* Default context prior over world states
* @param samples_prior states provided via R, sampled beforehand
* (e.g., by run-state-prior.wppl)
*
* @return {Distribution}
*/
var build_state_prior_from_data = function(samples_prior){
  var states = map(function(obj){
    var vs = obj["table.support"]
    var ps = obj["table.probs"]
    var Table = Categorical({vs, ps})
    var state = {r: obj.r, probability: obj.probability, table: Table,
                 bn_id: obj.bn_id, cn: obj.cn}
    return(state)
  }, samples_prior)

  var Prior = Infer({method: 'enumerate', model: function(){
                       var s = uniformDraw(states)
                       return(s)
                     }})
  return(Prior)
}
